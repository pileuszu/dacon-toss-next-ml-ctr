{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03. Model Definition\n",
        "\n",
        "## 개요\n",
        "LSTM + MLP 기반 CTR 예측 모델과 관련 함수들을 정의하는 노트북입니다.\n",
        "\n",
        "## 주요 구성\n",
        "- TabularSeqModel 클래스 정의\n",
        "- 모델 저장/로드 함수들\n",
        "- 모델 평가 함수\n",
        "\n",
        "**주의**: 이 노트북을 실행하기 전에 **01_setup_and_config.ipynb**와 **02_data_processing.ipynb**를 먼저 실행해주세요!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TabularSeqModel(nn.Module):\n",
        "    def __init__(self, d_features, lstm_hidden=32, hidden_units=[1024, 512, 256, 128], dropout=0.2):\n",
        "        super().__init__()\n",
        "        # 모든 비-시퀀스 피처에 BN\n",
        "        self.bn_x = nn.BatchNorm1d(d_features)\n",
        "        # seq: 숫자 시퀀스 → LSTM\n",
        "        self.lstm = nn.LSTM(input_size=1, hidden_size=lstm_hidden, batch_first=True)\n",
        "\n",
        "        # 최종 MLP\n",
        "        input_dim = d_features + lstm_hidden\n",
        "        layers = []\n",
        "        for h in hidden_units:\n",
        "            layers += [nn.Linear(input_dim, h), nn.ReLU(), nn.Dropout(dropout)]\n",
        "            input_dim = h\n",
        "        layers += [nn.Linear(input_dim, 1)]\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x_feats, x_seq, seq_lengths):\n",
        "        # 비-시퀀스 피처\n",
        "        x = self.bn_x(x_feats)\n",
        "\n",
        "        # 시퀀스 → LSTM (pack)\n",
        "        x_seq = x_seq.unsqueeze(-1)  # (B, L, 1)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(\n",
        "            x_seq, seq_lengths.cpu(), batch_first=True, enforce_sorted=False\n",
        "        )\n",
        "        _, (h_n, _) = self.lstm(packed)\n",
        "        h = h_n[-1]                  # (B, lstm_hidden)\n",
        "\n",
        "        z = torch.cat([x, h], dim=1)\n",
        "        return self.mlp(z).squeeze(1)  # logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Save & Load Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_model(model, model_path, model_config=None, optimizer=None, scheduler=None, feature_cols=None, training_history=None):\n",
        "    \"\"\"\n",
        "    확장된 모델 저장 함수 - Enhanced Gradient Descent를 위한 완전한 체크포인트\n",
        "    \"\"\"\n",
        "    checkpoint = {\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'model_config': model_config,\n",
        "        'timestamp': datetime.now().isoformat()\n",
        "    }\n",
        "    \n",
        "    # Optimizer state 저장 (연속 학습을 위해)\n",
        "    if optimizer is not None:\n",
        "        checkpoint['optimizer_state_dict'] = optimizer.state_dict()\n",
        "    \n",
        "    # Scheduler state 저장\n",
        "    if scheduler is not None:\n",
        "        checkpoint['scheduler_state_dict'] = scheduler.state_dict()\n",
        "        \n",
        "    # Feature columns 저장 (추론 시 사용)\n",
        "    if feature_cols is not None:\n",
        "        checkpoint['feature_cols'] = feature_cols\n",
        "        \n",
        "    # Training history 저장\n",
        "    if training_history is not None:\n",
        "        checkpoint['training_history'] = training_history\n",
        "    \n",
        "    torch.save(checkpoint, model_path)\n",
        "    print(f\"Enhanced checkpoint saved to: {model_path}\")\n",
        "\n",
        "def load_model_for_inference(model_path, d_features=None, device='cpu'):\n",
        "    \"\"\"\n",
        "    추론용 모델 로드 함수 - feature_cols 자동 추출 지원\n",
        "    \"\"\"\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
        "        \n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "    \n",
        "    # Feature columns가 체크포인트에 저장되어 있으면 사용\n",
        "    if 'feature_cols' in checkpoint:\n",
        "        if d_features is None:\n",
        "            d_features = len(checkpoint['feature_cols'])\n",
        "        print(f\"Features from checkpoint: {d_features}\")\n",
        "    \n",
        "    # 모델 설정 로드\n",
        "    if 'model_config' in checkpoint and checkpoint['model_config']:\n",
        "        config = checkpoint['model_config']\n",
        "        model = TabularSeqModel(\n",
        "            d_features=d_features,\n",
        "            lstm_hidden=config.get('lstm_hidden', 64),\n",
        "            hidden_units=config.get('hidden_units', [256, 128]),\n",
        "            dropout=config.get('dropout', 0.2)\n",
        "        )\n",
        "        print(f\"Model config: LSTM={config.get('lstm_hidden', 64)}, Hidden={config.get('hidden_units', [256, 128])}\")\n",
        "    else:\n",
        "        model = TabularSeqModel(\n",
        "            d_features=d_features,\n",
        "            lstm_hidden=64,\n",
        "            hidden_units=[256, 128],\n",
        "            dropout=0.2\n",
        "        )\n",
        "    \n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.to(device)\n",
        "    \n",
        "    print(f\"Model loaded from: {model_path}\")\n",
        "    if 'timestamp' in checkpoint:\n",
        "        print(f\"Model timestamp: {checkpoint['timestamp']}\")\n",
        "    \n",
        "    return model, checkpoint.get('feature_cols', None)\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion, device):\n",
        "    \"\"\"모델 평가 함수\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    num_batches = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for xs, seqs, lens, ys in data_loader:\n",
        "            xs, seqs, lens, ys = xs.to(device), seqs.to(device), lens.to(device), ys.to(device)\n",
        "            \n",
        "            outputs = model(xs, seqs, lens)\n",
        "            loss = criterion(outputs, ys)\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "    \n",
        "    avg_loss = total_loss / num_batches\n",
        "    return avg_loss\n",
        "\n",
        "print(\"Model definition functions loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
