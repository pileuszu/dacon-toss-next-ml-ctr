{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21874c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "196b9148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_parquet_10pieces(src_path, dst_dir, columns=None, batch_size=10_000):\n",
    "    \"\"\"\n",
    "    - Parquet 파일을 10개의 조각으로 분할하여 저장\n",
    "    - pandas 변환 없이 Arrow 배치만 처리 → 메모리 안전\n",
    "    - columns로 필요한 컬럼만 추려 메모리 추가 절약 가능\n",
    "    \"\"\"\n",
    "    pf = pq.ParquetFile(src_path)\n",
    "    total = pf.metadata.num_rows\n",
    "    piece_size = total // 10  # 각 조각의 크기\n",
    "    \n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "    \n",
    "    for piece in range(10):\n",
    "        writer = None\n",
    "        remaining = piece_size\n",
    "        written = 0\n",
    "        start_idx = piece * piece_size\n",
    "        \n",
    "        # 마지막 조각은 나머지 모든 행을 포함\n",
    "        if piece == 9:\n",
    "            remaining = total - (piece_size * 9)\n",
    "            \n",
    "        piece_num = piece + 1\n",
    "        dst_path = os.path.join(dst_dir, f\"part_{piece_num:02d}.parquet\")\n",
    "        \n",
    "        for batch in pf.iter_batches(batch_size=batch_size, columns=columns):\n",
    "            if start_idx > 0:\n",
    "                start_idx -= len(batch)\n",
    "                continue\n",
    "                \n",
    "            if remaining <= 0:\n",
    "                break\n",
    "                \n",
    "            n = len(batch)\n",
    "            if n > remaining:\n",
    "                batch = batch.slice(0, remaining)\n",
    "                n = remaining\n",
    "                \n",
    "            if writer is None:\n",
    "                writer = pq.ParquetWriter(dst_path, batch.schema, compression=\"zstd\", use_dictionary=True)\n",
    "                \n",
    "            writer.write_table(pa.Table.from_batches([batch]))\n",
    "            remaining -= n\n",
    "            written += n\n",
    "\n",
    "        if writer is not None:\n",
    "            writer.close()\n",
    "            \n",
    "        print(f\"Piece {piece_num}: wrote_rows={written:,} ({written/total*100:.2f}%) -> {dst_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ba4ff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piece 1: wrote_rows=1,070,417 (10.00%) -> ../../data/processed/split_data\\part_01.parquet\n",
      "Piece 2: wrote_rows=1,070,417 (10.00%) -> ../../data/processed/split_data\\part_02.parquet\n",
      "Piece 3: wrote_rows=1,070,417 (10.00%) -> ../../data/processed/split_data\\part_03.parquet\n",
      "Piece 4: wrote_rows=1,070,417 (10.00%) -> ../../data/processed/split_data\\part_04.parquet\n",
      "Piece 5: wrote_rows=1,070,417 (10.00%) -> ../../data/processed/split_data\\part_05.parquet\n",
      "Piece 6: wrote_rows=1,070,417 (10.00%) -> ../../data/processed/split_data\\part_06.parquet\n",
      "Piece 7: wrote_rows=1,070,417 (10.00%) -> ../../data/processed/split_data\\part_07.parquet\n",
      "Piece 8: wrote_rows=1,070,417 (10.00%) -> ../../data/processed/split_data\\part_08.parquet\n",
      "Piece 9: wrote_rows=1,070,417 (10.00%) -> ../../data/processed/split_data\\part_09.parquet\n",
      "Piece 10: wrote_rows=1,064,179 (9.94%) -> ../../data/processed/split_data\\part_10.parquet\n"
     ]
    }
   ],
   "source": [
    "src_path = \"../../data/raw/train.parquet\"\n",
    "dst_dir = \"../../data/processed/split_data\"\n",
    "split_parquet_10pieces(src_path, dst_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dacon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
