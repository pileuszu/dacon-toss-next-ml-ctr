{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02. Data Processing Functions\n",
        "\n",
        "## 개요\n",
        "데이터 로딩, 전처리, Dataset/DataLoader 관련 함수들을 정의하는 노트북입니다.\n",
        "\n",
        "## 주요 기능\n",
        "- Split 데이터 로딩 및 다운샘플링\n",
        "- Feature column 추출\n",
        "- PyTorch Dataset/DataLoader 정의\n",
        "- Collate 함수들\n",
        "\n",
        "**주의**: 이 노트북을 실행하기 전에 **01_setup_and_config.ipynb**를 먼저 실행해주세요!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading & Preprocessing Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_and_downsample_data(file_path, downsample_ratio=2):\n",
        "    \"\"\"\n",
        "    Split 데이터를 로드하고 다운샘플링 수행\n",
        "    \"\"\"\n",
        "    print(f\"Loading data from: {file_path}\")\n",
        "    \n",
        "    # 데이터 로드\n",
        "    df = pd.read_parquet(file_path, engine=\"pyarrow\")\n",
        "    print(f\"Original shape: {df.shape}\")\n",
        "    \n",
        "    # clicked == 1 데이터\n",
        "    clicked_1 = df[df['clicked'] == 1]\n",
        "    \n",
        "    # clicked == 0 데이터에서 동일 개수 x downsample_ratio 만큼 무작위 추출\n",
        "    clicked_0_count = len(clicked_1) * downsample_ratio\n",
        "    clicked_0 = df[df['clicked'] == 0]\n",
        "    \n",
        "    if len(clicked_0) < clicked_0_count:\n",
        "        # clicked=0 데이터가 부족한 경우 모든 데이터 사용\n",
        "        print(f\"Warning: Not enough clicked=0 data. Using all {len(clicked_0)} samples.\")\n",
        "        sampled_0 = clicked_0\n",
        "    else:\n",
        "        sampled_0 = clicked_0.sample(n=clicked_0_count, random_state=42)\n",
        "    \n",
        "    # 두 데이터프레임 합치기\n",
        "    result = pd.concat([clicked_1, sampled_0], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    \n",
        "    print(f\"Downsampled shape: {result.shape}\")\n",
        "    print(f\"Clicked=0: {len(result[result['clicked']==0])}, Clicked=1: {len(result[result['clicked']==1])}\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "def get_feature_columns(df):\n",
        "    \"\"\"피처 컬럼 추출\"\"\"\n",
        "    FEATURE_EXCLUDE = {\"clicked\", \"seq\", \"ID\"}\n",
        "    return [c for c in df.columns if c not in FEATURE_EXCLUDE]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PyTorch Dataset Class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ClickDataset(Dataset):\n",
        "    def __init__(self, df, feature_cols, seq_col, target_col=None, has_target=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.feature_cols = feature_cols\n",
        "        self.seq_col = seq_col\n",
        "        self.target_col = target_col\n",
        "        self.has_target = has_target\n",
        "\n",
        "        # 비-시퀀스 피처: 전부 연속값으로\n",
        "        self.X = self.df[self.feature_cols].astype(float).fillna(0).values\n",
        "\n",
        "        # 시퀀스: 문자열 그대로 보관 (lazy 파싱)\n",
        "        self.seq_strings = self.df[self.seq_col].astype(str).values\n",
        "\n",
        "        if self.has_target:\n",
        "            self.y = self.df[self.target_col].astype(np.float32).values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.X[idx], dtype=torch.float)\n",
        "\n",
        "        # 전체 시퀀스 사용 (빈 시퀀스만 방어)\n",
        "        s = self.seq_strings[idx]\n",
        "        if s and s != 'nan':\n",
        "            try:\n",
        "                arr = np.fromstring(s, sep=\",\", dtype=np.float32)\n",
        "            except:\n",
        "                arr = np.array([], dtype=np.float32)\n",
        "        else:\n",
        "            arr = np.array([], dtype=np.float32)\n",
        "\n",
        "        if arr.size == 0:\n",
        "            arr = np.array([0.0], dtype=np.float32)  # 빈 시퀀스 방어\n",
        "\n",
        "        seq = torch.from_numpy(arr)  # shape (seq_len,)\n",
        "\n",
        "        if self.has_target:\n",
        "            y = torch.tensor(self.y[idx], dtype=torch.float)\n",
        "            return x, seq, y\n",
        "        else:\n",
        "            return x, seq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collate_fn_train(batch):\n",
        "    xs, seqs, ys = zip(*batch)\n",
        "    xs = torch.stack(xs)\n",
        "    ys = torch.stack(ys)\n",
        "    seqs_padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True, padding_value=0.0)\n",
        "    seq_lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
        "    seq_lengths = torch.clamp(seq_lengths, min=1)  # 빈 시퀀스 방지\n",
        "    return xs, seqs_padded, seq_lengths, ys\n",
        "\n",
        "def collate_fn_infer(batch):\n",
        "    xs, seqs = zip(*batch)\n",
        "    xs = torch.stack(xs)\n",
        "    seqs_padded = nn.utils.rnn.pad_sequence(seqs, batch_first=True, padding_value=0.0)\n",
        "    seq_lengths = torch.tensor([len(s) for s in seqs], dtype=torch.long)\n",
        "    seq_lengths = torch.clamp(seq_lengths, min=1)\n",
        "    return xs, seqs_padded, seq_lengths\n",
        "\n",
        "print(\"Data processing functions loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Collate Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
