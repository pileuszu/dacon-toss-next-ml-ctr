{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 05. Inference & Submission Generation\n",
        "\n",
        "## 개요\n",
        "학습된 모델을 사용하여 테스트 데이터에 대한 추론을 수행하고 제출 파일을 생성하는 노트북입니다.\n",
        "\n",
        "## 주요 기능\n",
        "- 저장된 모델 자동 로드 (feature 정보 포함)\n",
        "- 테스트 데이터 배치별 추론\n",
        "- 메모리 효율적 처리\n",
        "- 베이스라인 호환 제출 파일 생성\n",
        "\n",
        "## 실행 방법\n",
        "1. **학습 후 바로 실행**: 04번 노트북 실행 직후 → 변수들이 메모리에 있음\n",
        "2. **별도 실행**: 01→02→03→05 순서로 실행 → 저장된 모델 자동 로드\n",
        "\n",
        "**주의**: 이 노트북을 실행하기 전에 **01**, **02**, **03** 노트북을 먼저 실행해주세요!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 및 feature 정보 확인/로드\n",
        "print(\"=\"*80)\n",
        "print(\"STARTING ENHANCED INFERENCE WITH TRAINED MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# 04번 노트북에서 이어받은 변수들이 있는지 확인\n",
        "if 'training_completed' in locals() and 'trained_model' in locals() and 'trained_feature_cols' in locals():\n",
        "    print(\"Using variables from training session:\")\n",
        "    print(f\"- training_completed: {training_completed}\")\n",
        "    print(f\"- trained_model: Available\")\n",
        "    print(f\"- trained_feature_cols: {len(trained_feature_cols)} features\")\n",
        "    \n",
        "    model = trained_model\n",
        "    inference_feature_cols = trained_feature_cols\n",
        "    print(\"Model and features loaded from training session!\")\n",
        "    \n",
        "else:\n",
        "    print(\"Loading model from saved checkpoint...\")\n",
        "    \n",
        "    # 최종 모델 경로\n",
        "    final_model_path = os.path.join(CFG['MODELS_PATH'], f\"{CFG['MODEL_NAME']}_enhanced_final.pth\")\n",
        "    \n",
        "    if not os.path.exists(final_model_path):\n",
        "        print(f\"Final model not found: {final_model_path}\")\n",
        "        print(\"Trying to find latest checkpoint...\")\n",
        "        \n",
        "        # 체크포인트 파일 찾기\n",
        "        checkpoint_files = glob.glob(os.path.join(CFG['MODELS_PATH'], f\"{CFG['MODEL_NAME']}_enhanced_checkpoint_*.pth\"))\n",
        "        if checkpoint_files:\n",
        "            final_model_path = max(checkpoint_files)  # 가장 최근 체크포인트\n",
        "            print(f\"Using latest checkpoint: {os.path.basename(final_model_path)}\")\n",
        "        else:\n",
        "            raise FileNotFoundError(\"No trained model found! Please run 04_training.ipynb first.\")\n",
        "    \n",
        "    # 모델 로드\n",
        "    model, inference_feature_cols = load_model_for_inference(final_model_path, device=device)\n",
        "    \n",
        "    if inference_feature_cols is None:\n",
        "        print(\"Feature columns not found in checkpoint. Extracting from split data...\")\n",
        "        # Split 파일에서 feature 정보 추출\n",
        "        split_files = glob.glob(os.path.join(CFG['SPLIT_DATA_PATH'], \"part_*.parquet\"))\n",
        "        if split_files:\n",
        "            temp_df = pd.read_parquet(split_files[0], nrows=1000)\n",
        "            inference_feature_cols = get_feature_columns(temp_df)\n",
        "            del temp_df\n",
        "            clear_memory()\n",
        "        else:\n",
        "            raise FileNotFoundError(\"No split files found for feature extraction!\")\n",
        "    \n",
        "    print(f\"Model loaded successfully!\")\n",
        "    print(f\"Features available: {len(inference_feature_cols)}\")\n",
        "\n",
        "print(f\"Final feature count: {len(inference_feature_cols)}\")\n",
        "print(f\"Memory after model loading: {get_memory_usage()}\")\n",
        "model.eval()  # 추론 모드로 설정\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 테스트 데이터 로드\n",
        "print(\"=\"*60)\n",
        "print(\"Loading Test Data\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "test_df = pd.read_parquet(\"../../data/raw/test.parquet\", engine=\"pyarrow\")\n",
        "print(f\"Test data shape: {test_df.shape}\")\n",
        "\n",
        "# ID 컬럼 따로 보관 (제출용)\n",
        "test_ids = test_df['ID'].copy()\n",
        "\n",
        "# ID 컬럼 제거 (feature에 포함되지 않음)\n",
        "test_df = test_df.drop(columns=['ID'])\n",
        "\n",
        "print(f\"Test data shape after removing ID: {test_df.shape}\")\n",
        "print(f\"Memory after test data loading: {get_memory_usage()}\")\n",
        "\n",
        "# 데이터셋 및 DataLoader 생성\n",
        "seq_col = \"seq\"\n",
        "test_dataset = ClickDataset(test_df, inference_feature_cols, seq_col, has_target=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, collate_fn=collate_fn_infer)\n",
        "\n",
        "print(f\"Test dataset size: {len(test_dataset):,}\")\n",
        "print(f\"Number of batches: {len(test_loader)}\")\n",
        "print(f\"Batch size: {CFG['BATCH_SIZE']:,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def perform_inference(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    메모리 효율적 배치별 추론 수행\n",
        "    \"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"Starting Model Inference\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    predictions = []\n",
        "    start_time = datetime.now()\n",
        "    batch_times = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        inference_progress = tqdm(test_loader, desc=\"Inference Progress\")\n",
        "        for batch_idx, (xs, seqs, lens) in enumerate(inference_progress):\n",
        "            batch_start = datetime.now()\n",
        "            \n",
        "            xs, seqs, lens = xs.to(device), seqs.to(device), lens.to(device)\n",
        "            \n",
        "            # 모델 예측\n",
        "            logits = model(xs, seqs, lens)\n",
        "            probs = torch.sigmoid(logits)\n",
        "            \n",
        "            predictions.append(probs.cpu())\n",
        "            \n",
        "            # 배치 처리 시간 기록\n",
        "            batch_time = (datetime.now() - batch_start).total_seconds()\n",
        "            batch_times.append(batch_time)\n",
        "            \n",
        "            # Progress bar 업데이트\n",
        "            inference_progress.set_postfix({\n",
        "                'batch': f\"{batch_idx+1}/{len(test_loader)}\",\n",
        "                'time': f\"{batch_time:.3f}s\"\n",
        "            })\n",
        "            \n",
        "            # 주기적 메모리 정리 (100배치마다)\n",
        "            if (batch_idx + 1) % 100 == 0:\n",
        "                clear_memory()\n",
        "                avg_batch_time = np.mean(batch_times[-100:])\n",
        "                print(f\"Processed {batch_idx+1} batches | Avg batch time: {avg_batch_time:.3f}s\")\n",
        "    \n",
        "    # 예측 결과 합치기\n",
        "    final_predictions = torch.cat(predictions).numpy()\n",
        "    \n",
        "    # 통계 정보\n",
        "    end_time = datetime.now()\n",
        "    total_time = (end_time - start_time).total_seconds()\n",
        "    avg_batch_time = np.mean(batch_times)\n",
        "    \n",
        "    print(f\"\\nInference completed successfully!\")\n",
        "    print(f\"Total inference time: {total_time:.2f} seconds\")\n",
        "    print(f\"Average batch time: {avg_batch_time:.3f} seconds\")\n",
        "    print(f\"Predictions shape: ({final_predictions.shape[0]:,},)\")\n",
        "    \n",
        "    # 예측 통계\n",
        "    print(f\"Prediction statistics:\")\n",
        "    print(f\"   Min: {final_predictions.min():.6f}\")\n",
        "    print(f\"   Max: {final_predictions.max():.6f}\")\n",
        "    print(f\"   Mean: {final_predictions.mean():.6f}\")\n",
        "    print(f\"   Std: {final_predictions.std():.6f}\")\n",
        "    print(f\"   Median: {np.median(final_predictions):.6f}\")\n",
        "    \n",
        "    # 예측 분포 확인\n",
        "    bins = np.arange(0, 1.1, 0.1)\n",
        "    hist, _ = np.histogram(final_predictions, bins=bins)\n",
        "    print(f\"Prediction distribution:\")\n",
        "    for i in range(len(bins)-1):\n",
        "        pct = hist[i] / len(final_predictions) * 100\n",
        "        print(f\"   {bins[i]:.1f}-{bins[i+1]:.1f}: {hist[i]:,} ({pct:.1f}%)\")\n",
        "    \n",
        "    return final_predictions\n",
        "\n",
        "# 추론 실행\n",
        "print(\"Starting inference...\")\n",
        "test_predictions = perform_inference(model, test_loader, device)\n",
        "print(f\"Memory after inference: {get_memory_usage()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Submission File Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 제출 파일 생성 (베이스라인 호환 양식)\n",
        "print(\"=\"*60)\n",
        "print(\"Creating Submission File\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# 기존 sample_submission.csv 파일 읽기\n",
        "sample_submission = pd.read_csv('../../data/raw/sample_submission.csv')\n",
        "print(f\"Sample submission shape: {sample_submission.shape}\")\n",
        "\n",
        "# 예측 결과로 clicked 컬럼 업데이트\n",
        "submission_df = sample_submission.copy()\n",
        "submission_df['clicked'] = test_predictions\n",
        "\n",
        "# ID 순서 확인 (안전성 체크)\n",
        "if not submission_df['ID'].equals(test_ids):\n",
        "    print(\"WARNING: ID order mismatch! Re-aligning...\")\n",
        "    # ID를 기준으로 병합\n",
        "    test_results = pd.DataFrame({'ID': test_ids, 'clicked': test_predictions})\n",
        "    submission_df = sample_submission[['ID']].merge(test_results, on='ID', how='left')\n",
        "\n",
        "print(f\"Submission DataFrame shape: {submission_df.shape}\")\n",
        "print(f\"Submission predictions stats:\")\n",
        "print(f\"  Min: {test_predictions.min():.6f}\")\n",
        "print(f\"  Max: {test_predictions.max():.6f}\")\n",
        "print(f\"  Mean: {test_predictions.mean():.6f}\")\n",
        "print(f\"  Std: {test_predictions.std():.6f}\")\n",
        "\n",
        "# outputs 폴더 확인 및 생성\n",
        "output_dir = '../../outputs'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# 기존 제출 파일 확인하여 번호 결정 (베이스라인과 동일한 방식)\n",
        "existing_files = [f for f in os.listdir(output_dir) if f.startswith('submission_') and f.endswith('.csv')]\n",
        "\n",
        "if len(existing_files) == 0:\n",
        "    next_num = 1\n",
        "    print(\"No existing submission files found. Starting with submission_1.csv\")\n",
        "else:\n",
        "    nums = [int(f.split('_')[1].split('.')[0]) for f in existing_files]\n",
        "    next_num = max(nums) + 1\n",
        "    print(f\"Found {len(existing_files)} existing submission files. Next: submission_{next_num}.csv\")\n",
        "\n",
        "# 새로운 파일명으로 저장 (베이스라인과 동일한 양식)\n",
        "output_path = os.path.join(output_dir, f'submission_{next_num}.csv')\n",
        "\n",
        "submission_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Submission file saved: {output_path}\")\n",
        "print(f\"Submission shape: {submission_df.shape}\")\n",
        "print(f\"File: submission_{next_num}.csv\")\n",
        "\n",
        "# 최종 메모리 정리\n",
        "clear_memory()\n",
        "print(f\"Final memory usage: {get_memory_usage()}\")\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"INFERENCE AND SUBMISSION COMPLETED SUCCESSFULLY!\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Submission file: submission_{next_num}.csv\")\n",
        "print(f\"Location: {output_path}\")\n",
        "print(f\"Ready for submission!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
