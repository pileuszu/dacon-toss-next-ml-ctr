{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 01. Setup and Configuration\n",
        "\n",
        "## 개요\n",
        "라이브러리 import, 설정값 정의, 메모리 관리 함수 등 기본 설정을 담당하는 노트북입니다.\n",
        "\n",
        "## 주요 구성\n",
        "- 필수 라이브러리 import\n",
        "- CFG 설정값 정의  \n",
        "- Device 설정 및 Seed 고정\n",
        "- 메모리 관리 유틸리티 함수들\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Library Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import gc\n",
        "from datetime import datetime\n",
        "import glob\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration Settings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CFG = {\n",
        "    'BATCH_SIZE': 4096,\n",
        "    'EPOCHS_PER_SPLIT': 3,  # 각 split 데이터당 에포크 수\n",
        "    'LEARNING_RATE': 1e-3,\n",
        "    'SEED': 42,\n",
        "    'DOWNSAMPLE_RATIO': 2,  # clicked=0 데이터를 clicked=1의 몇 배로 샘플링할지\n",
        "    'SPLIT_DATA_PATH': '../../data/processed/split_data/',\n",
        "    'MODELS_PATH': '../../models/',\n",
        "    'MODEL_NAME': 'ctr_lstm_mlp_model',\n",
        "    # Enhanced Gradient Descent Parameters\n",
        "    'WEIGHT_DECAY': 1e-5,\n",
        "    'GRADIENT_CLIP_NORM': 1.0,\n",
        "    'CATASTROPHIC_THRESHOLD': 1.2,\n",
        "    'LR_REDUCTION_FACTOR': 0.7,\n",
        "    'SAVE_CHECKPOINT_EVERY': 3\n",
        "}\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# models 폴더가 없으면 생성\n",
        "os.makedirs(CFG['MODELS_PATH'], exist_ok=True)\n",
        "print(f\"Model directory: {CFG['MODELS_PATH']}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Seed Setting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(CFG['SEED'])  # Seed 고정\n",
        "print(f\"Seed set to: {CFG['SEED']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Memory Management Utilities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clear_memory():\n",
        "    \"\"\"메모리 정리를 위한 함수\"\"\"\n",
        "    gc.collect()\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "def get_memory_usage():\n",
        "    \"\"\"현재 GPU 메모리 사용량 확인\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        allocated = torch.cuda.memory_allocated() / 1024**2  # MB\n",
        "        cached = torch.cuda.memory_reserved() / 1024**2  # MB\n",
        "        return f\"GPU Memory - Allocated: {allocated:.1f}MB, Cached: {cached:.1f}MB\"\n",
        "    return \"CPU mode - No GPU memory tracking\"\n",
        "\n",
        "# 초기 메모리 상태 확인\n",
        "print(f\"Initial memory usage: {get_memory_usage()}\")\n",
        "print(\"\\nSetup completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
